{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNQiSujBfjWj"
      },
      "source": [
        "# **Week 4 Assignment: Saliency Maps**\n",
        "\n",
        "Welcome to the final programming exercise of this course! For this week, your task is to adapt the [Cats vs Dogs](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) Class Activation Map ungraded lab (the second ungraded lab of this week) and make it generate saliency maps instead.\n",
        "\n",
        "As discussed in the lectures, a saliency map shows the pixels which greatly impacts the classification of an image.\n",
        "- This is done by getting the gradient of the loss with respect to changes in the pixel values, then plotting the results.\n",
        "- From there, you can see if your model is looking at the correct features when classifying an image.\n",
        "  - For example, if you're building a dog breed classifier, you should be wary if your saliency map shows strong pixels outside the dog itself (e.g. sky, grass, dog house, etc...).\n",
        "\n",
        "In this assignment you will be given prompts but less starter code to fill in in.\n",
        "- It's good practice for you to try and write as much of this code as you can from memory and from searching the web.\n",
        "- **Whenever you feel stuck**, please refer back to the labs of this week to see how to write the code. In particular, look at:\n",
        "  - **Ungraded Lab 2: Cats vs Dogs CAM**\n",
        "  - **Ungraded Lab 3: Saliency**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDHISSfBq40T"
      },
      "source": [
        "### Download test files and weights\n",
        "\n",
        "Let's begin by first downloading files we will be using for this lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Laatr1c6lr1w"
      },
      "outputs": [],
      "source": [
        "# # Download the same test files from the Cats vs Dogs ungraded lab\n",
        "# !wget -O cat1.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/cat1.jpeg\n",
        "# !wget -O cat2.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/cat2.jpeg\n",
        "# !wget -O catanddog.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/catanddog.jpeg\n",
        "# !wget -O dog1.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/dog1.jpeg\n",
        "# !wget -O dog2.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/dog2.jpeg\n",
        "\n",
        "# # Download prepared weights\n",
        "# !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1kipXTxesGJKGY1B8uSPRvxROgOH90fih' -O 0_epochs.h5\n",
        "# !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1oiV6tjy5k7h9OHGTQaf0Ohn3FmF-uOs1' -O 15_epochs.h5\n",
        "\n",
        "import wget\n",
        "\n",
        "def download_file(url, filename):\n",
        "    wget.download(url, out=filename)\n",
        "\n",
        "# Download the same test files from the Cats vs Dogs ungraded lab\n",
        "download_file('https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/cat1.jpeg', 'cat1.jpg')\n",
        "download_file('https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/cat2.jpeg', 'cat2.jpg')\n",
        "download_file('https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/catanddog.jpeg', 'catanddog.jpg')\n",
        "download_file('https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/dog1.jpeg', 'dog1.jpg')\n",
        "download_file('https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/dog2.jpeg', 'dog2.jpg')\n",
        "\n",
        "# Download prepared weights\n",
        "download_file('https://docs.google.com/uc?export=download&id=1kipXTxesGJKGY1B8uSPRvxROgOH90fih', '0_epochs.h5')\n",
        "download_file('https://docs.google.com/uc?export=download&id=1oiV6tjy5k7h9OHGTQaf0Ohn3FmF-uOs1', '15_epochs.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g24L3lKwqb3E"
      },
      "source": [
        "### Import the required packages\n",
        "\n",
        "Please import:\n",
        "\n",
        "  * Tensorflow\n",
        "  * Tensorflow Datasets\n",
        "  * Numpy\n",
        "  * Matplotlib's PyPlot\n",
        "  * Keras Models API classes you will be using\n",
        "  * Keras layers you will be using\n",
        "  * OpenCV (cv2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X86LKLvpBO2S"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th4dA3I8-9Ue"
      },
      "source": [
        "### Download and prepare the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1hujOK9rDyU"
      },
      "source": [
        "#### Load Cats vs Dogs\n",
        "\n",
        "* Required: Use Tensorflow Datasets to fetch the `cats_vs_dogs` dataset.\n",
        "  * Use the first 80% of the *train* split of the said dataset to create your training set.\n",
        "  * Set the `as_supervised` flag to create `(image, label)` pairs.\n",
        "    \n",
        "* Optional: You can create validation and test sets from the remaining 20% of the *train* split of `cats_vs_dogs` (i.e. you already used 80% for the train set). This is if you intend to train the model beyond what is required for submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7w5HNdoHBQv_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ./cats_vs_dogs\\cats_vs_dogs\\4.0.1...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Dl Size...: 100%|██████████| 786/786 [05:44<00:00,  2.28 MiB/s]\n",
            "Dl Completed...: 100%|██████████| 1/1 [05:44<00:00, 344.96s/ url]\n"
          ]
        },
        {
          "ename": "RecursionError",
          "evalue": "maximum recursion depth exceeded",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data and create the train set (optional: val and test sets)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m train_data, info \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcats_vs_dogs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain[:80\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_supervised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./cats_vs_dogs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcats_vs_dogs\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain[80\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m:90\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, as_supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./cats_vs_dogs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m test_data \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcats_vs_dogs\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain[-10\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m:]\u001b[39m\u001b[38;5;124m'\u001b[39m, as_supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./cats_vs_dogs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:649\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03m`tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m    Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    643\u001b[0m dbuilder \u001b[38;5;241m=\u001b[39m _fetch_builder(\n\u001b[0;32m    644\u001b[0m     name,\n\u001b[0;32m    645\u001b[0m     data_dir,\n\u001b[0;32m    646\u001b[0m     builder_kwargs,\n\u001b[0;32m    647\u001b[0m     try_gcs,\n\u001b[0;32m    648\u001b[0m )\n\u001b[1;32m--> 649\u001b[0m \u001b[43m_download_and_prepare_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m   as_dataset_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:508\u001b[0m, in \u001b[0;36m_download_and_prepare_builder\u001b[1;34m(dbuilder, download, download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m    507\u001b[0m   download_and_prepare_kwargs \u001b[38;5;241m=\u001b[39m download_and_prepare_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m--> 508\u001b[0m   \u001b[43mdbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:691\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mread_from_directory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 691\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m   \u001b[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[0;32m    697\u001b[0m   \u001b[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[0;32m    698\u001b[0m   \u001b[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[0;32m    699\u001b[0m   \u001b[38;5;66;03m# when reading from package data.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdownload_size \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownloaded_size\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1547\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1546\u001b[0m   optional_pipeline_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1547\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=unexpected-keyword-arg\u001b[39;49;00m\n\u001b[0;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptional_pipeline_kwargs\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1550\u001b[0m \u001b[38;5;66;03m# TODO(tfds): Could be removed once all datasets are migrated.\u001b[39;00m\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;66;03m# https://github.com/tensorflow/datasets/issues/2537\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;66;03m# Legacy mode (eventually convert list[SplitGeneratorLegacy] -> dict)\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m split_builder\u001b[38;5;241m.\u001b[39mnormalize_legacy_split_generators(\n\u001b[0;32m   1554\u001b[0m     split_generators\u001b[38;5;241m=\u001b[39msplit_generators,\n\u001b[0;32m   1555\u001b[0m     generator_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_examples,\n\u001b[0;32m   1556\u001b[0m     is_beam\u001b[38;5;241m=\u001b[39m\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, BeamBasedBuilder),\n\u001b[0;32m   1557\u001b[0m )\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\image_classification\\cats_vs_dogs.py:81\u001b[0m, in \u001b[0;36mCatsVsDogs._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split_generators\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager):\n\u001b[1;32m---> 81\u001b[0m   path \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_URL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m   \u001b[38;5;66;03m# There is no predefined train/val/test split for this dataset.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     85\u001b[0m       tfds\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mSplitGenerator(\n\u001b[0;32m     86\u001b[0m           name\u001b[38;5;241m=\u001b[39mtfds\u001b[38;5;241m.\u001b[39mSplit\u001b[38;5;241m.\u001b[39mTRAIN,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m       ),\n\u001b[0;32m     91\u001b[0m   ]\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:601\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# Add progress bar to follow the download state\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_downloader\u001b[38;5;241m.\u001b[39mtqdm():\n\u001b[1;32m--> 601\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_promise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:831\u001b[0m, in \u001b[0;36m_map_promise\u001b[1;34m(map_fn, all_inputs)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    828\u001b[0m all_promises \u001b[38;5;241m=\u001b[39m tree_utils\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m    829\u001b[0m     map_fn, all_inputs\n\u001b[0;32m    830\u001b[0m )  \u001b[38;5;66;03m# Apply the function\u001b[39;00m\n\u001b[1;32m--> 831\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtree_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_promises\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait promises\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tree\\__init__.py:428\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    426\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m--> 428\u001b[0m                     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:832\u001b[0m, in \u001b[0;36m_map_promise.<locals>.<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    828\u001b[0m all_promises \u001b[38;5;241m=\u001b[39m tree_utils\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m    829\u001b[0m     map_fn, all_inputs\n\u001b[0;32m    830\u001b[0m )  \u001b[38;5;66;03m# Apply the function\u001b[39;00m\n\u001b[0;32m    831\u001b[0m res \u001b[38;5;241m=\u001b[39m tree_utils\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m--> 832\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m p: \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, all_promises\n\u001b[0;32m    833\u001b[0m )  \u001b[38;5;66;03m# Wait promises\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\promise\\promise.py:512\u001b[0m, in \u001b[0;36mPromise.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    510\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target()\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(timeout \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_TIMEOUT)\n\u001b[1;32m--> 512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target_settled_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_raise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\promise\\promise.py:516\u001b[0m, in \u001b[0;36mPromise._target_settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_target_settled_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, _raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# type: (bool) -> Any\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settled_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_raise\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\promise\\promise.py:226\u001b[0m, in \u001b[0;36mPromise._settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _raise:\n\u001b[0;32m    225\u001b[0m     raise_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fulfillment_handler0\n\u001b[1;32m--> 226\u001b[0m     \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraise_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_traceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fulfillment_handler0\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\promise\\promise.py:87\u001b[0m, in \u001b[0;36mtry_catch\u001b[1;34m(handler, *args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_catch\u001b[39m(handler, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# type: (Callable, Any, Any) -> Union[Tuple[Any, None], Tuple[None, Tuple[Exception, Optional[TracebackType]]]]\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     89\u001b[0m         tb \u001b[38;5;241m=\u001b[39m exc_info()[\u001b[38;5;241m2\u001b[39m]\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:408\u001b[0m, in \u001b[0;36mDownloadManager._download.<locals>.<lambda>\u001b[1;34m(dl_result)\u001b[0m\n\u001b[0;32m    402\u001b[0m   future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_downloader\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[0;32m    403\u001b[0m       url, download_tmp_dir, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_ssl\n\u001b[0;32m    404\u001b[0m   )\n\u001b[0;32m    406\u001b[0m \u001b[38;5;66;03m# Post-process the result\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mthen(\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m dl_result: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_or_validate_checksums\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomputed_url_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_url_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_url_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m )\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:473\u001b[0m, in \u001b[0;36mDownloadManager._register_or_validate_checksums\u001b[1;34m(self, path, url, expected_url_info, computed_url_info, checksum_path, url_path)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    456\u001b[0m   \u001b[38;5;66;03m# Eventually validate checksums\u001b[39;00m\n\u001b[0;32m    457\u001b[0m   \u001b[38;5;66;03m# Note:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    463\u001b[0m   \u001b[38;5;66;03m#   download). This is expected as it might mean the downloaded file\u001b[39;00m\n\u001b[0;32m    464\u001b[0m   \u001b[38;5;66;03m#   was corrupted. Note: The tmp file isn't deleted to allow inspection.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m   _validate_checksums(\n\u001b[0;32m    466\u001b[0m       url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    467\u001b[0m       path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m       force_checksums_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force_checksums_validation,\n\u001b[0;32m    471\u001b[0m   )\n\u001b[1;32m--> 473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rename_and_get_final_dl_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_url_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_url_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomputed_url_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputed_url_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchecksum_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:497\u001b[0m, in \u001b[0;36mDownloadManager._rename_and_get_final_dl_path\u001b[1;34m(self, url, path, expected_url_info, computed_url_info, checksum_path, url_path)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Eventually rename the downloaded file if checksums were recorded.\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# `path` can be:\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# * Manually downloaded\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# * (cached) checksum_path\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;66;03m# * (cached) url_path\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# * `tmp_dir/file` (downloaded path)\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manual_dir \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_relative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manual_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m path  \u001b[38;5;66;03m# Manually downloaded data\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;241m==\u001b[39m checksum_path:  \u001b[38;5;66;03m# Path already at final destination\u001b[39;00m\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\etils\\epath\\abstract_path.py:78\u001b[0m, in \u001b[0;36mPath.is_relative_to\u001b[1;34m(self, *other)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the path is relative to another path or False.\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:679\u001b[0m, in \u001b[0;36mPurePath.relative_to\u001b[1;34m(self, other, walk_up, *_deprecated)\u001b[0m\n\u001b[0;32m    677\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_segments(other, \u001b[38;5;241m*\u001b[39m_deprecated)\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([other] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(other\u001b[38;5;241m.\u001b[39mparents)):\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_relative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m walk_up:\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\etils\\epath\\abstract_path.py:78\u001b[0m, in \u001b[0;36mPath.is_relative_to\u001b[1;34m(self, *other)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the path is relative to another path or False.\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:679\u001b[0m, in \u001b[0;36mPurePath.relative_to\u001b[1;34m(self, other, walk_up, *_deprecated)\u001b[0m\n\u001b[0;32m    677\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_segments(other, \u001b[38;5;241m*\u001b[39m_deprecated)\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([other] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(other\u001b[38;5;241m.\u001b[39mparents)):\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_relative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m walk_up:\n",
            "    \u001b[1;31m[... skipping similar frames: Path.is_relative_to at line 78 (731 times), PurePath.relative_to at line 679 (730 times)]\u001b[0m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:679\u001b[0m, in \u001b[0;36mPurePath.relative_to\u001b[1;34m(self, other, walk_up, *_deprecated)\u001b[0m\n\u001b[0;32m    677\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_segments(other, \u001b[38;5;241m*\u001b[39m_deprecated)\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([other] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(other\u001b[38;5;241m.\u001b[39mparents)):\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_relative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m walk_up:\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\etils\\epath\\abstract_path.py:78\u001b[0m, in \u001b[0;36mPath.is_relative_to\u001b[1;34m(self, *other)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the path is relative to another path or False.\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:677\u001b[0m, in \u001b[0;36mPurePath.relative_to\u001b[1;34m(self, other, walk_up, *_deprecated)\u001b[0m\n\u001b[0;32m    672\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport for supplying more than one positional argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    673\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto pathlib.PurePath.relative_to() is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    674\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduled for removal in Python \u001b[39m\u001b[38;5;132;01m{remove}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    675\u001b[0m     warnings\u001b[38;5;241m.\u001b[39m_deprecated(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpathlib.PurePath.relative_to(*args)\u001b[39m\u001b[38;5;124m\"\u001b[39m, msg,\n\u001b[0;32m    676\u001b[0m                          remove\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m14\u001b[39m))\n\u001b[1;32m--> 677\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_segments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_deprecated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([other] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(other\u001b[38;5;241m.\u001b[39mparents)):\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_relative_to(path):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:385\u001b[0m, in \u001b[0;36mPurePath.with_segments\u001b[1;34m(self, *pathsegments)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_segments\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mpathsegments):\n\u001b[0;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct a new path object from any number of path-like objects.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;124;03m    Subclasses may override this method to customize how new path objects\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    are created from methods like `iterdir()`.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpathsegments\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\etils\\epath\\gpath.py:81\u001b[0m, in \u001b[0;36m_GPath.__new__\u001b[1;34m(cls, *parts)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m: Type[_P], \u001b[38;5;241m*\u001b[39mparts: PathLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _P:\n\u001b[1;32m---> 81\u001b[0m   full_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m full_path\u001b[38;5;241m.\u001b[39mstartswith(_URI_PREFIXES):\n\u001b[0;32m     83\u001b[0m     prefix, _ \u001b[38;5;241m=\u001b[39m full_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m'\u001b[39m, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\etils\\epath\\gpath.py:81\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m: Type[_P], \u001b[38;5;241m*\u001b[39mparts: PathLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _P:\n\u001b[1;32m---> 81\u001b[0m   full_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parts)\n\u001b[0;32m     82\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m full_path\u001b[38;5;241m.\u001b[39mstartswith(_URI_PREFIXES):\n\u001b[0;32m     83\u001b[0m     prefix, _ \u001b[38;5;241m=\u001b[39m full_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m'\u001b[39m, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\etils\\epath\\gpath.py:133\u001b[0m, in \u001b[0;36m_GPath.__fspath__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__fspath__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 133\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path_str\u001b[49m\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\etils\\epath\\gpath.py:126\u001b[0m, in \u001b[0;36m_GPath._path_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_path_str\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    125\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the `__fspath__` string representation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m   uri_scheme \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_uri_scheme\u001b[49m\n\u001b[0;32m    127\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m uri_scheme:  \u001b[38;5;66;03m# pylint: disable=using-constant-test\u001b[39;00m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_PATH\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri_scheme\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m2\u001b[39m:])\n",
            "File \u001b[1;32md:\\Studi\\MBKM\\bangkit-machine-learning\\Tensorflow-advanced-techniques\\c3-advanced-computer-vision\\week-4\\tf2_15_tfds4_9_4\\Lib\\site-packages\\etils\\epath\\gpath.py:99\u001b[0m, in \u001b[0;36m_GPath._uri_scheme\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_uri_scheme\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m     98\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m---> 99\u001b[0m       \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    100\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    101\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _URI_SCHEMES\n\u001b[0;32m    102\u001b[0m   ):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    104\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
          ]
        }
      ],
      "source": [
        "# Load the data and create the train set (optional: val and test sets)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "# train_data, info = tfds.load('cats_vs_dogs', split='train[:80%]', as_supervised=True, with_info=True, data_dir='./cats_vs_dogs')\n",
        "# validation_data = tfds.load('cats_vs_dogs', split='train[80%:90%]', as_supervised=True, data_dir='./cats_vs_dogs')\n",
        "# test_data = tfds.load('cats_vs_dogs', split='train[-10%:]', as_supervised=True, data_dir='./cats_vs_dogs')\n",
        "\n",
        "train_data, info = tfds.load('cats_vs_dogs', split='train[:80%]', with_info=True, data_dir='./cats_vs_dogs')\n",
        "validation_data = tfds.load('cats_vs_dogs', split='train[80%:90%]', data_dir='./cats_vs_dogs')\n",
        "test_data = tfds.load('cats_vs_dogs', split='train[-10%:]', data_dir='./cats_vs_dogs')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXp0mV5Rbo76"
      },
      "source": [
        "#### Create preprocessing function\n",
        "\n",
        "Define a function that takes in an image and label. This will:\n",
        "  * cast the image to float32\n",
        "  * normalize the pixel values to [0, 1]\n",
        "  * resize the image to 300 x 300\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRkrL2aK2_UZ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def augmentimages(image, label):\n",
        "  # YOUR CODE HERE\n",
        "  \n",
        "  # Cast the image to the float\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  \n",
        "  # Resize to 300 x 300\n",
        "  image = image / 255.0\n",
        "  \n",
        "  # Normalize the pixel values\n",
        "  image = tf.image.resize(image, (300, 300))\n",
        "  \n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzvF61GV32k_"
      },
      "source": [
        "#### Preprocess the training set\n",
        "\n",
        "Use the `map()` and pass in the method that you just defined to preprocess the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpNEfDKM353a"
      },
      "outputs": [],
      "source": [
        "augmented_training_data = train_data.map(augmentimages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4nFaMIMbrvA"
      },
      "source": [
        "#### Create batches of the training set.\n",
        "\n",
        "This is already provided for you. Normally, you will want to shuffle the training set. But for predictability in the grading, we will simply create the batches.\n",
        "\n",
        "```Python\n",
        "# Shuffle the data if you're working on your own personal project\n",
        "train_batches = augmented_training_data.shuffle(1024).batch(32)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POhDDPBY3vnL"
      },
      "outputs": [],
      "source": [
        "train_batches = augmented_training_data.batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za5HxgT1_Cw6"
      },
      "source": [
        "### Build the Cats vs Dogs classifier\n",
        "\n",
        "You'll define a model that is nearly the same as the one in the Cats vs. Dogs CAM lab.\n",
        "* Please preserve the architecture of the model in the Cats vs Dogs CAM lab (this week's second lab) except for the final `Dense` layer.\n",
        "* You should modify the Cats vs Dogs model at the last dense layer to output 2 neurons instead of 1.\n",
        "  - This is because you will adapt the `do_salience()` function from the lab and that works with one-hot encoded labels.\n",
        "  - You can do this by changing the `units` argument of the output Dense layer from 1 to 2, with one for each of the classes (i.e. cats and dogs).\n",
        "  - You should choose an activation that outputs a probability for each of the 2 classes (i.e. categories), where the sum of the probabilities adds up to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoyCA80GBSlG"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv2D(16, input_shape=(300, 300, 3), kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktnATyllHXC4"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```txt\n",
        "Model: \"sequential\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d (Conv2D)              (None, 300, 300, 16)      448       \n",
        "_________________________________________________________________\n",
        "max_pooling2d (MaxPooling2D) (None, 150, 150, 16)      0         \n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 150, 150, 32)      4640      \n",
        "_________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_2 (Conv2D)            (None, 75, 75, 64)        18496     \n",
        "_________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 64)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_3 (Conv2D)            (None, 37, 37, 128)       73856     \n",
        "_________________________________________________________________\n",
        "global_average_pooling2d (Gl (None, 128)               0         \n",
        "_________________________________________________________________\n",
        "dense (Dense)                (None, 2)                 258       \n",
        "=================================================================\n",
        "Total params: 97,698\n",
        "Trainable params: 97,698\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6nou82P_b5d"
      },
      "source": [
        "### Create a function to generate the saliency map\n",
        "\n",
        "Complete the `do_salience()` function below to save the **normalized_tensor** image.\n",
        "- The major steps are listed as comments below.\n",
        "  - Each section may involve multiple lines of code.\n",
        "- Try your best to write the code from memory or by performing web searches.\n",
        "  - Whenever you get stuck, you can review the \"saliency\" lab (the third lab of this week) to help remind you of what code to write"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKbvh3bl9vnG"
      },
      "outputs": [],
      "source": [
        "def do_salience(image, model, label, prefix):\n",
        "  '''\n",
        "  Generates the saliency map of a given image.\n",
        "\n",
        "  Args:\n",
        "    image (file) -- picture that the model will classify\n",
        "    model (keras Model) -- your cats and dogs classifier\n",
        "    label (int) -- ground truth label of the image\n",
        "    prefix (string) -- prefix to add to the filename of the saliency map\n",
        "  '''\n",
        "\n",
        "  # Read the image and convert channel order from BGR to RGB\n",
        "  # YOUR CODE HERE\n",
        "  # Read the image\n",
        "  image = cv2.imread(image)\n",
        "  \n",
        "  # Convert channel order from BGR to RGB\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Resize the image to 300 x 300 and normalize pixel values to the range [0, 1]\n",
        "  # YOUR CODE HERE\n",
        "  image = cv2.resize(image, (300, 300))\n",
        "  image = image / 255.0\n",
        "\n",
        "  # Add an additional dimension (for the batch), and save this in a new variable\n",
        "  # YOUR CODE HERE\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "\n",
        "  # Declare the number of classes\n",
        "  # YOUR CODE HERE\n",
        "  num_classes = 2\n",
        "\n",
        "  # Define the expected output array by one-hot encoding the label\n",
        "  # The length of the array is equal to the number of classes\n",
        "  # YOUR CODE HERE\n",
        "  expected_output = tf.one_hot([label] * image.shape[0], num_classes)\n",
        "\n",
        "  # Witin the GradientTape block:\n",
        "  # Cast the image as a tf.float32\n",
        "  # Use the tape to watch the float32 image\n",
        "  # Get the model's prediction by passing in the float32 image\n",
        "  # Compute an appropriate loss\n",
        "  # between the expected output and model predictions.\n",
        "  # you may want to print the predictions to see if the probabilities adds up to 1\n",
        "  # YOUR CODE HERE\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Cast image to tf.float32\n",
        "    inputs = tf.cast(image, tf.float32)\n",
        "    \n",
        "    # Watch the input pixels\n",
        "    tape.watch(inputs)\n",
        "    \n",
        "    # Get model prediction\n",
        "    predictions = model(inputs)\n",
        "    \n",
        "    # get the loss\n",
        "    loss = categorical_crossentropy(\n",
        "      expected_output, predictions\n",
        "    )\n",
        "\n",
        "  # get the gradients of the loss with respect to the model's input image\n",
        "  # YOUR CODE HERE\n",
        "  gradients = tape.gradient(loss, inputs)\n",
        "\n",
        "  # generate the grayscale tensor\n",
        "  # YOUR CODE HERE\n",
        "  grayscale_tensor = tf.reduce_sum(tf.abs(gradients), axis=-1)\n",
        "\n",
        "  # normalize the pixel values to be in the range [0, 255].\n",
        "  # the max value in the grayscale tensor will be pushed to 255.\n",
        "  # the min value will be pushed to 0.\n",
        "  # Use the formula: 255 * (x - min) / (max - min)\n",
        "  # Use tf.reduce_max, tf.reduce_min\n",
        "  # Cast the tensor as a tf.uint8\n",
        "  # YOUR CODE HERE\n",
        "  normalized_tensor = tf.cast(\n",
        "    255 * (grayscale_tensor - tf.reduce_min(grayscale_tensor)) / (tf.reduce_max(grayscale_tensor) - tf.reduce_min(grayscale_tensor)),\n",
        "    tf.uint8\n",
        "  )\n",
        "\n",
        "  # Remove dimensions that are size 1\n",
        "  # YOUR CODE HERE\n",
        "  normalized_tensor = tf.squeeze(normalized_tensor)\n",
        "\n",
        "  # plot the normalized tensor\n",
        "  # Set the figure size to 8 by 8\n",
        "  # do not display the axis\n",
        "  # use the 'gray' colormap\n",
        "  # This code is provided for you.\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(normalized_tensor, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "  # optional: superimpose the saliency map with the original image, then display it.\n",
        "  # we encourage you to do this to visualize your results better\n",
        "  # YOUR CODE HERE\n",
        "  # Menggabungkan peta saliensi dengan gambar asli\n",
        "  # Mengubah gambar asli menjadi float untuk penggabungan\n",
        "  # original_float = tf.cast(image, tf.float32)\n",
        "  \n",
        "  # # Mengubah peta saliensi menjadi float dan menyesuaikan dimensinya agar sesuai dengan gambar asli\n",
        "  # saliency_float = tf.cast(normalized_tensor, tf.float32)\n",
        "  # saliency_float = tf.expand_dims(saliency_float, axis=-1)\n",
        "  \n",
        "  # # Menggabungkan peta saliensi dengan gambar asli dengan memberikan transparansi 50% pada peta saliensi\n",
        "  # superimposed_image = original_float + 0.5 * saliency_float\n",
        "  # superimposed_image = tf.clip_by_value(superimposed_image, 0, 255)  # Memastikan nilai pixel valid\n",
        "  \n",
        "  # # Menampilkan gambar yang telah digabungkan\n",
        "  # plt.figure(figsize=(8, 8))\n",
        "  # plt.axis('off')\n",
        "  # plt.imshow(tf.cast(superimposed_image, tf.uint8))\n",
        "  # plt.show()\n",
        "  # --- optional ---\n",
        "\n",
        "  # save the normalized tensor image to a file. this is already provided for you.\n",
        "  salient_image_name = prefix + image\n",
        "  normalized_tensor = tf.expand_dims(normalized_tensor, -1)\n",
        "  normalized_tensor = tf.io.encode_jpeg(normalized_tensor, quality=100, format='grayscale')\n",
        "  writer = tf.io.write_file(salient_image_name, normalized_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li1idRy-parp"
      },
      "source": [
        "### Generate saliency maps with untrained model\n",
        "\n",
        "As a sanity check, you will load initialized (i.e. untrained) weights and use the function you just implemented.\n",
        "- This will check if you built the model correctly and are able to create a saliency map.\n",
        "\n",
        "If an error pops up when loading the weights or the function does not run, please check your implementation for bugs.\n",
        "- You can check the ungraded labs of this week.\n",
        "\n",
        "Please apply your `do_salience()` function on the following image files:\n",
        "\n",
        "* `cat1.jpg`\n",
        "* `cat2.jpg`\n",
        "* `catanddog.jpg`\n",
        "* `dog1.jpg`\n",
        "* `dog2.jpg`\n",
        "\n",
        "Cats will have the label `0` while dogs will have the label `1`.\n",
        "- For the catanddog, please use `0`.\n",
        "- For the prefix of the salience images that will be generated, please use the prefix `epoch0_salient`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k39fF4n8fgG0"
      },
      "outputs": [],
      "source": [
        "# load initial weights\n",
        "model.load_weights('0_epochs.h5')\n",
        "\n",
        "# generate the saliency maps for the 5 test images\n",
        "# YOUR CODE HERE\n",
        "images = ['cat1.jpg', 'cat2.jpg', 'catanddog.jpg', 'dog1.jpg', 'dog2.jpg']\n",
        "labels = [0, 0, 0, 1, 1]\n",
        "prefix = 'epoch0_salient'\n",
        "\n",
        "for image, label in zip(images, labels):\n",
        "  do_salience(image, model, label, prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kcdyut5E2Tk"
      },
      "source": [
        "With untrained weights, you will see something like this in the output.\n",
        "- You will see strong pixels outside the cat that the model uses that when classifying the image.\n",
        "- After training that these will slowly start to localize to features inside the pet.\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1h5wP52lwbBUMVLlsgyb-tQl_I9eu42X7' alt='saliency'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZhZgd0x_JvN"
      },
      "source": [
        "### Configure the model for training\n",
        "\n",
        "Use `model.compile()` to define the loss, metrics and optimizer.\n",
        "\n",
        "* Choose a loss function for the model to use when training.\n",
        "  - For `model.compile()` the ground truth labels from the training set are passed to the model as **integers** (i.e. 0 or 1) as opposed to one-hot encoded vectors.\n",
        "  - The model predictions are class probabilities.\n",
        "  - You can browse the [tf.keras.losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses) and determine which one is best used for this case.\n",
        "  - Remember that you can pass the function as a string (e.g. `loss = 'loss_function_a'`).\n",
        "\n",
        "* For metrics, you can measure `accuracy`.\n",
        "* For the optimizer, please use [RMSProp](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop).\n",
        "  - Please use the default learning rate of `0.001`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkyWZ5KdBo-z"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "model.compile(\n",
        "    loss=categorical_crossentropy,\n",
        "    metrics=['accuracy'],\n",
        "    optimizer=RMSprop(learning_rate=0.001)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otIoJJw7_ZFN"
      },
      "source": [
        "### Train your model\n",
        "\n",
        "Please pass in the training batches and train your model for just **3** epochs.\n",
        "- **Note:** Please do not exceed 3 epochs because the grader will expect 3 epochs when grading your output.\n",
        "  - After submitting your zipped folder for grading, feel free to continue training to improve your model.\n",
        "\n",
        "We have loaded pre-trained weights for 15 epochs so you can get a better output when you visualize the saliency maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YSNp7k7BqfL"
      },
      "outputs": [],
      "source": [
        "# load pre-trained weights\n",
        "model.load_weights('15_epochs.h5')\n",
        "\n",
        "# train the model for just 3 epochs\n",
        "# YOUR CODE HERE\n",
        "model.fit(train_batches, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tTqtLN3tQJx"
      },
      "source": [
        "### Generate saliency maps at 18 epochs\n",
        "\n",
        "You will now use your `do_salience()` function again on the same test images. Please use the same parameters as before but this time, use the prefix `salient`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXFtabyVhIKN"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "for img, label in zip(images, labels):\n",
        "    do_salience(img, model, label, 'salient')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGTFcfEgM6aV"
      },
      "source": [
        "You should see that the strong pixels are now very less than the ones you generated earlier. Moreover, most of them are now found on features within the pet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPtx-u4u_jL5"
      },
      "source": [
        "### Zip the images for grading\n",
        "\n",
        "Please run the cell below to zip the normalized tensor images you generated at 18 epochs. If you get an error, please check that you have files named:\n",
        "\n",
        "* salientcat1.jpg\n",
        "* salientcat2.jpg\n",
        "* salientcatanddog.jpg\n",
        "* salientdog1.jpg\n",
        "* salientdog2.jpg\n",
        "\n",
        "Afterwards, please download the **images.zip** from the Files bar on the left."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-MhcA8Uh8H_"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "!rm images.zip\n",
        "\n",
        "filenames = ['cat1.jpg', 'cat2.jpg', 'catanddog.jpg', 'dog1.jpg', 'dog2.jpg']\n",
        "\n",
        "# writing files to a zipfile\n",
        "with ZipFile('images.zip','w') as zip:\n",
        "  for file in filenames:\n",
        "    zip.write('salient' + file)\n",
        "\n",
        "print(\"images.zip generated!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMOgx-N55A6p"
      },
      "source": [
        "### Optional: Saliency Maps at 95 epochs\n",
        "\n",
        "We have pre-trained weights generated at 95 epochs and you can see the difference between the maps you generated at 18 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elUfhSmMvJZh"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=14vFpBJsL_TNQeugX8vUTv8dYZxn__fQY' -O 95_epochs.h5\n",
        "\n",
        "model.load_weights('95_epochs.h5')\n",
        "\n",
        "do_salience('cat1.jpg', model, 0, \"epoch95_salient\")\n",
        "do_salience('cat2.jpg', model, 0, \"epoch95_salient\")\n",
        "do_salience('catanddog.jpg', model, 0, \"epoch95_salient\")\n",
        "do_salience('dog1.jpg', model, 1, \"epoch95_salient\")\n",
        "do_salience('dog2.jpg', model, 1, \"epoch95_salient\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuKLdQhvAaTd"
      },
      "source": [
        "**Congratulations on completing this week's assignment! Please go back to the Coursera classroom and upload the zipped folder to be graded.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
